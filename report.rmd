---
title: "CYO-project | HarvardX"
author: "Marco Schicker"
date: "14 5 2021"
output: pdf_document
 toc: true
    toc_depth: 2
    number_sections: true

---

``` {r setup, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, Message=FALSE, fig.width=6, fig.height=4)

#######INSTALL PACKAGES#######
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(corrplot)) install.packages("corrplot", repos = "http://cran.us.r-project.org")
if(!require(gam)) install.packages("gam", repos = "http://cran.us.r-project.org")


library(tidyverse)
library(caret)
library(data.table)
library(dplyr)
library(stringr)
library(ggplot2)
library(lubridate)
library(corrplot)
library(rpart)
library(matrixStats)
library(gam)
library(splines)
---

```


# Executive summary  

The current corona crisis and past crisis like in 2008 have shown over and over again that companies that are not able to react fast enough and have too much capital bound along their supply chain have a problem to adapt and an increased risk for bankruptcy. 
In order to form resilient, effective and efficient supply chains lead times are a very central key performance indicator (KPI) to optimize. Any change you make to a process will take at least one avg lead time to show effect. If your lead times are at 100 working days - which is not so uncommon and can be much longer in many cases - you will have a reaction time of almost half a year for most measures to kick in in case of a crisis. This can be too long for some companies and will make a timely check of measures almost impossible. 

The goal of this project is to predict Order-to-Casch (O2C) lead times at the time of ordering by the customer, depending on product, the sales channel, sales organization, the production site and seasonal trends, along with what data we can get out of the ERP. In order to do this we will analyze system logs of all sales orders from the last couple years.


# Background information  

## Lead time  

When talking about lead time we make a difference between the length and the volatility/reliability of lead time.
  
- A short lead time of material throughout the whole supply chain means that material takes the most direct route between producer and customer, not being stocked, reworked, stopped for any reason other than having value added to it. This concept of focusing on lead time is well-known from LEAN Management. Any activity done to the product that doesn´t increase the value from customer perspective is considered waste. The target is to eliminate waste as much as possible and reduce necessary waste as much as possible.  
- A low volatility of lead time makes a supply chain more predictable, regardless of how short or long it may be. This will help any company to give reliable information to customers, provide a good Level of Service (LoS) and overall increase trust in the company´s performance. Further, a predictable supply chain enables us to reduce safety stocks and hence, reduce the capital employed significantly. Last but not least a low volatility makes it much easier to automate and level production flow. In order to compare very different lead times we use the coefficient of variation, which is the    

  
## Order tracking  
Most companies work with so called order status updates once a concrete order has passed particular milestones, e.g. manufactured, packed, shipped, delivered, etc... Based on the business model and the setup of the supply chain these stati differ and are adapted to the company´s needs. The data can be stored across different systems (ERP, CRM, web shop, 3rd party applications) and needs to be stitched together to create a conclusive data set.

## Company description  
The company that we will use to showcase ML in lead time prediction is a european supplier of shading solutions. Manufacturing sites and sales organizations exist in multiple countries. The business model follows a mixed approach of B2B2C and B2C, that means running own organizations that provide consulting, installation and service to final customers as well as selling product to retailers. This makes it more challenging as all orders run through the same factories but serve different business models and different supply chains. The final target is the same though: reducing lead time to be agile and reduce the effects of having a lot of capital bound in the supply chain.




# Methods & Analysis
The process to train the models consists of the following basic steps:  

- Data import
- Data exploration, cleaning and visualization
- Data mutation
- Creating training and test set
- Training and comparing different models
- Validation of best model

## Data import  
The data provided by the company has been widely anonymized and shared on a web site as a CSV file. It consists of two different files:  
1. "O2C.csv" - a file showing _one observation per order status change_ and including information like timestamp, corresponding project ID, salesdata, volumes etc...
2. "project.csv" - a file showing _one observation per projectID_ linking projects to direct sales organizations and making it possible to use these as predictors. the project-file is leftjoined to the O2c file to combine all data in one table.

The data is only roughly cleaned and needs to be altered in order to be used.


## Data exploration, cleaning and visualization

In order to work with the data set it is analyzed and altered.

### Overall analysis
To get a first overview about the data the following table is created:
```{r}

```
We can see that the O2C data table consists of the following columns:  
- country - the country in which the order was sold
- DS.PB - direct sales (=our own shops) or partner business (=retailer)
- statusID - the different stati that any order (=salesID) can go through
- status_name - the corresponding short description of the statusID
- created_dt - timestamp automatically generated when the status change has been made
- corr_project - binary to mark correction projects
- PROJID - project ID. Any project can have 1 or more SalesIDs associated to it. An order cannot be finalized if there are other unfinished orders within a project.
- salesID - an order line identifier. It is created by appending an order number to the projectID
- itemID - The product sold within the order line. Can be empty in some cases if there are multiple items included. This is true only for some sales channels
- sum_qty - how many items are sold
- sum_m2 - how many m² have been sold within this order
- days on status - time in days that an order stays in a certain status.
- channel_name - detailed information which organization or planner is selling the order
- divisiongroup - high level differentiation if it is a service, installation or retail project
- division - mid level differentiation between 17 divisions. 

The dimensions of the data file are as follows:  
```{r}

```


The data classes are shown in the following table
```{r}

```


The Status IDs are especially interesting as they mark different gates that our order passes. We will concentrate on the following statusIDs:  

- A000 - an order is being created
- A100 - an order is opened, having defined products, delivery dates, etc.
- A105 - an order is visible to the plant and is being scheduled for production. At this stage the order should ideally flow all the way through the supply chain until we can invoice the customer
- A300 - production is started
- A310 - production is finished an goods are ready to ship
- A320 - re-stocked item shipped. 
- A330 - goods are delivered to the customer site and installation is in process
- A340 - installation is finished. Waiting for invoice proposal. In this state an order needs to wait for potential other orders that are included in the same project.
- A400 - invoice proposal finished
- A410 - invoice sent to customer. This status is the last one in the system but unfortunately not part of the data received. However we can calculate it by taking the A400 timestamp and add the duration in A400 in days

For this analysis we will start with A105, because that is the status from which onward the order must flow. In status A000 and A100 the order can be used for prediction but doesn´t cause much trouble if staying there for a long time. We will keep A000, because the data shows that most orders pass through this state (in theory all must pass through this state). We will use the timestamp of the A000 state to create predictors for year, month and day. A100 will not be used for calculation of total lead time but will be kept for analysis purposes and to visualize the production funnel. Further we will drop A320 as it is a not widely used intermediate statusID, there is only 1 occurrence. 


### Exclude special cases (correction projects, "90x" products, Service orders and Inter company orders)  
So called _correction projects_ are entered in the system to handle any quality deviations that include manufacturing or delivery for a customer. Since these correction projects follow a different workflow they are excluded from the analysis
  
Not all products shown in the column _itemID_ are real products that need to be manufactured, shipped and installed. Some represent hours of administrative work that can be invoiced to customer. Those itemIDs start with a _90x_ and will be also excluded from the analysis.  

Orders and projects that are marked as _SERV_ in the column _divisiongroup_ show service-orders which are an important part of the business model but also follow a separate workflow and therefore are also excluded from this analysis.

Lastly, the data also include _intercompany orders_ which need to be excluded from analysis as they have a digital twin in one of the countries.

### Find duplicate entries
```{r}

```




### Convert to wide data

The data table shows one observation per status change of any order. Since we want to predict the total lead time for a complete order we need one observation per order (=salesID) and transform our data frame so that we have the different timestamps per status change in columns and add a column for total lead time. 

We can find `r n_distinct(O2C$salesID)` individual orders in the data set.  

#### Prepare data

The problem we face is the fact that even though in theory an order cannot pass through the same status twice we can find exactly those cases in the data set. Out of `r nrow(O2C)` rows we can identify `r O2C %>% find_duplicates(salesID, statusID) %>% nrow()` cases of duplicate combinations of salesID and statusID.


In order to handle this we will only keep the earlier status change per order.
```{r}
O2C <- O2C %>% arrange(created_dt) %>% distinct(salesID, statusID, .keep_all=TRUE)
```


After eliminating the problem cases we can create the wide data frame without running into issues.
```{r}
O2C_wide <- O2C %>% pivot_wider(
                    id_cols = c(salesID, country, DS.PB, division, divisiongroup, PROJID, itemID, sum_qty, sum_m2, channel_name), 
                    names_from = statusID, 
                    values_from = c(created_dt, days_on_status)
                    )
```

  
#### Add new columns  

To prepare for modeling we will create new columns to differentiate between different kind of orders  
- total_lt - total lead time from beginning to end, defined as the difference between the timestamp A400 and A105 plus the duration in status A400. Remember that an invoice sent is status A410, for which we don´t have a timestamp. 
- order_complete - a binary variable which is 1 if there is a A400 timestamp and 0 if not. 0 means that the order has dropped out of the system at some point. 

#### Check new wide data frame

As a first check we need to find out how many orders are complete and exclude all incomplete orders. As check criteria we assume that any complete order has a valid timestamp for statusID=A400 (= invoice proposal created). We can see that only a proportion of `r mean(O2C_wide$order_complete)` of all orders are complete. A deep dive reveals the amount of incomplete orders per year.
```{r incomplete orders per year}



```

These orders are deleted from the data set.
The next check is for NA´s in any of the statusID columns. An _NA_ means that the corresponding order has not gone through a particular statusID. That can be ok and normal in some cases as orders from partner business usually don´t pass some of the orderstatus for direct sales (e.g. installation completed because installation is not part of their business model). However, we can see that there are quite a few orders that have never been created or opened in the first place (NA in column A000 or A100). These orders might have been opened in previous years, so we need to erase them as well to not bias the data.

For the next check we need to look back at the purpose of this project and combine it with the insights gained.. 
We want to predict lead times at the time of ordering. Because we don´t know the preferred delivery date we assume our supply chain should deliver according to its capabilities. That is why we need to look at orders that also pass the status A105 which means that the product has been planned in the factory. As we could see we still have some orders that don´t pass that status. 
For those orders we will copy the date from A100 to the A105 column.



### Find predictors that are highly correlated and remove if necessary


### Remove predictors with near zero variation


### Average and distribution  
The total lead time is distributed among the whole data as follows:
```{r}

```



### Distributions of orders per order status 


## Insights gained  

A first insight is that the system data contains a very big amount of orders that obviously didn´t follow the standard process. We started out with `r orig_salesID` unique orders and deleted the following:  
1. 




## Modeling approach




# Results



# Conclusion